{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_dataset(dataset, test_split=0.25):\n",
    "    train_idx, test_idx = train_test_split(list(range(len(dataset))), test_size=test_split)\n",
    "    datasets = {}\n",
    "    datasets['train'] = torch.utils.data.Subset(dataset, train_idx)\n",
    "    datasets['test'] = torch.utils.data.Subset(dataset, test_idx)\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "data_path = '../../data/fruit/'\n",
    "fruit_class = {0:'banana', 1:'grape', 2:'orange', 3:'strawberry', 4:'unknown'}\n",
    "print(os.listdir(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "EPOCH = 50\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "TEST_BATCH_SIZE = 4\n",
    "TEST_SIZE = 0.20\n",
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((200,200)),\n",
    "    transforms.RandomHorizontalFlip(p=1),\n",
    "    transforms.RandomVerticalFlip(p=1),\n",
    "    transforms.RandomAffine(30),\n",
    "    transforms.ColorJitter(contrast=(0.2, 3)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "inv_normalize = transforms.Normalize(\n",
    "   mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "   std=[1/0.229, 1/0.224, 1/0.225]\n",
    ")\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder(root=data_path, transform=transform)\n",
    "datasets = train_test_dataset(dataset, test_split=TEST_SIZE)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(datasets['train'], batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(datasets['test'], batch_size=TEST_BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(len(trainloader))\n",
    "print(len(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image show\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "ex_img, ex_label = iter(trainloader).next()\n",
    "for i, im in enumerate(ex_img):\n",
    "    ex_img[i] = inv_normalize(ex_img[i])\n",
    "img_grid = make_grid(ex_img).permute(1,2,0)\n",
    "plt.imshow(img_grid)\n",
    "print(ex_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "model_vgg16 = torchvision.models.vgg16(pretrained=True)\n",
    "\n",
    "for p in model_vgg16.features.parameters():\n",
    "    p.requires_grad = False\n",
    "    \n",
    "model_vgg16.classifier[6] = nn.Linear(4096, 5)\n",
    "\n",
    "    \n",
    "model_vgg16.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GPU 여부\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('We are using GPU')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('We are using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_vgg16.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Test\n",
    "with torch.no_grad():\n",
    "    model_vgg16.eval()\n",
    "    model_vgg16.to(device)\n",
    "    ex_img, ex_label = iter(trainloader).next()\n",
    "    ex_img, ex_label = ex_img.to(device), ex_label.to(device)\n",
    "    print(ex_img.size())\n",
    "    ex_output = model_vgg16(ex_img)\n",
    "    print(ex_output.max(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Traing\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "for e in range(EPOCH):\n",
    "    model_vgg16.train()\n",
    "    model_vgg16.to(device)\n",
    "    start_time = time.time()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(trainloader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_vgg16(images)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss\n",
    "        now = time.time()\n",
    "        print('\\r[%d/%d]-----[%d/%d] LOSS : %.3f------ Time : %d' \n",
    "              %(e+1, EPOCH, i+1, len(trainloader), running_loss, now - start_time), end = '')\n",
    "    if e==0:\n",
    "        running_time = now-start_time\n",
    "        print('\\n')\n",
    "        print(datetime.timedelta(seconds=running_time*EPOCH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "torch.save(model_vgg16.cpu().state_dict(), os.getcwd() + '/models/trained_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model_vgg16.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_vgg16.to(device)\n",
    "    for i, data in enumerate(testloader):\n",
    "        test_images, test_labels = data\n",
    "        test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "        \n",
    "        test_outputs = model_vgg16(test_images)\n",
    "        pred = test_outputs.argmax(dim=1, keepdim=True)\n",
    "        total += pred.size()[0]\n",
    "        correct += pred.eq(test_labels.view_as(pred)).sum().item()\n",
    "        \n",
    "print('The Accuracy of Model is %0.2f%%' % (correct / total * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16.eval()\n",
    "with torch.no_grad():\n",
    "    ex_img, ex_label = iter(testloader).next()\n",
    "    model_vgg16.to(device)\n",
    "    ex_img = ex_img.to(device)\n",
    "    output = model_vgg16(ex_img)\n",
    "\n",
    "ex_pred = output.argmax(dim=1)\n",
    "for i, im in enumerate(ex_img):\n",
    "    ex_img[i] = inv_normalize(ex_img[i])\n",
    "plt.imshow(make_grid(ex_img).permute(1,2,0).cpu())\n",
    "print('GroundTruth : ', ' '.join(fruit_class[ex_label[j].item()] for j in range(4)))\n",
    "print('Predicted : ', ' '.join(fruit_class[ex_pred[i].item()] for i in range(4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
